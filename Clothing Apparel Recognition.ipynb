{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=torchvision.datasets.FashionMNIST( \n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor()])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(train_data,1000,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image,label=sample \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image[0].squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2519c252a90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image[2].squeeze(),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()      # color channel initially =1 because grayscale\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5) #Kernel size=(5,5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5) # Color Channels=12\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120) \n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "    def forward(self, t):\n",
    "\n",
    "        # (2) hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        # (3) hidden conv layer\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        # (4) hidden linear layer\n",
    "        t = t.reshape(-1, 12 * 4 * 4) # 4*4 represents height and width of the image.\n",
    "        t = self.fc1(t)               # 28*28 got converted to 4*4 because of Pooling operations\n",
    "        t = F.relu(t)\n",
    "\n",
    "        # (5) hidden linear layer\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        # (6) output layer\n",
    "        t = self.out(t)\n",
    "\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.Adam(net.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 total_correct: 28706 loss: 90.61659210920334\n",
      "epoch 2 total_correct: 41241 loss: 48.644272804260254\n",
      "epoch 3 total_correct: 43952 loss: 41.78227323293686\n",
      "epoch 4 total_correct: 45396 loss: 37.935465693473816\n",
      "epoch 5 total_correct: 46541 loss: 35.29988259077072\n",
      "epoch 6 total_correct: 47316 loss: 33.233697444200516\n",
      "epoch 7 total_correct: 48101 loss: 31.55356827378273\n",
      "epoch 8 total_correct: 48775 loss: 30.128227949142456\n",
      "epoch 9 total_correct: 49333 loss: 28.885958164930344\n",
      "epoch 10 total_correct: 49830 loss: 27.7764151096344\n",
      "epoch 11 total_correct: 50306 loss: 26.69041681289673\n",
      "epoch 12 total_correct: 50429 loss: 26.23859778046608\n",
      "epoch 13 total_correct: 50790 loss: 25.369631946086884\n",
      "epoch 14 total_correct: 50877 loss: 24.866614043712616\n",
      "epoch 15 total_correct: 51193 loss: 24.198722779750824\n",
      "epoch 16 total_correct: 51312 loss: 23.847261488437653\n",
      "epoch 17 total_correct: 51397 loss: 23.59489005804062\n",
      "epoch 18 total_correct: 51743 loss: 22.88512548804283\n",
      "epoch 19 total_correct: 51868 loss: 22.380267709493637\n",
      "epoch 20 total_correct: 51987 loss: 22.007423758506775\n",
      "epoch 21 total_correct: 52172 loss: 21.66270136833191\n",
      "epoch 22 total_correct: 52277 loss: 21.44788271188736\n",
      "epoch 23 total_correct: 52332 loss: 21.077729523181915\n",
      "epoch 24 total_correct: 52378 loss: 20.96800199151039\n",
      "epoch 25 total_correct: 52497 loss: 20.500065982341766\n",
      "epoch 26 total_correct: 52558 loss: 20.411182522773743\n",
      "epoch 27 total_correct: 52661 loss: 20.250046104192734\n",
      "epoch 28 total_correct: 52708 loss: 19.931154310703278\n",
      "epoch 29 total_correct: 52846 loss: 19.697210729122162\n",
      "epoch 30 total_correct: 52927 loss: 19.574179023504257\n",
      "epoch 31 total_correct: 52989 loss: 19.383413672447205\n",
      "epoch 32 total_correct: 52991 loss: 19.198195219039917\n",
      "epoch 33 total_correct: 52899 loss: 19.41007113456726\n",
      "epoch 34 total_correct: 53111 loss: 18.895512014627457\n",
      "epoch 35 total_correct: 53174 loss: 18.83206281065941\n",
      "epoch 36 total_correct: 53188 loss: 18.66106629371643\n",
      "epoch 37 total_correct: 53254 loss: 18.471586763858795\n",
      "epoch 38 total_correct: 53325 loss: 18.351388663053513\n",
      "epoch 39 total_correct: 53278 loss: 18.41634500026703\n",
      "epoch 40 total_correct: 53394 loss: 18.048469334840775\n",
      "epoch 41 total_correct: 53465 loss: 17.9791356921196\n",
      "epoch 42 total_correct: 53412 loss: 17.949170023202896\n",
      "epoch 43 total_correct: 53565 loss: 17.581000924110413\n",
      "epoch 44 total_correct: 53738 loss: 17.312734827399254\n",
      "epoch 45 total_correct: 53665 loss: 17.36325539648533\n",
      "epoch 46 total_correct: 53610 loss: 17.36301150918007\n",
      "epoch 47 total_correct: 53699 loss: 17.22340928018093\n",
      "epoch 48 total_correct: 53779 loss: 17.06478588283062\n",
      "epoch 49 total_correct: 53675 loss: 17.09464505314827\n",
      "epoch 50 total_correct: 53901 loss: 16.686896339058876\n",
      "epoch 51 total_correct: 53987 loss: 16.530628636479378\n",
      "epoch 52 total_correct: 54003 loss: 16.413259148597717\n",
      "epoch 53 total_correct: 53954 loss: 16.46939466893673\n",
      "epoch 54 total_correct: 53919 loss: 16.588737785816193\n",
      "epoch 55 total_correct: 53972 loss: 16.52219232916832\n",
      "epoch 56 total_correct: 54068 loss: 16.224522694945335\n",
      "epoch 57 total_correct: 54004 loss: 16.251172333955765\n",
      "epoch 58 total_correct: 54072 loss: 16.048716738820076\n",
      "epoch 59 total_correct: 54166 loss: 15.912138521671295\n",
      "epoch 60 total_correct: 54171 loss: 15.905572801828384\n",
      "epoch 61 total_correct: 54162 loss: 15.77090099453926\n",
      "epoch 62 total_correct: 54329 loss: 15.471761301159859\n",
      "epoch 63 total_correct: 54332 loss: 15.45826531946659\n",
      "epoch 64 total_correct: 54293 loss: 15.509777441620827\n",
      "epoch 65 total_correct: 54366 loss: 15.469600290060043\n",
      "epoch 66 total_correct: 54461 loss: 15.201317325234413\n",
      "epoch 67 total_correct: 54503 loss: 15.061726853251457\n",
      "epoch 68 total_correct: 54446 loss: 15.072447195649147\n",
      "epoch 69 total_correct: 54542 loss: 14.987483501434326\n",
      "epoch 70 total_correct: 54499 loss: 14.877501279115677\n",
      "epoch 71 total_correct: 54579 loss: 14.751817435026169\n",
      "epoch 72 total_correct: 54594 loss: 14.831743881106377\n",
      "epoch 73 total_correct: 54497 loss: 14.967496261000633\n",
      "epoch 74 total_correct: 54696 loss: 14.493269264698029\n",
      "epoch 75 total_correct: 54678 loss: 14.551716983318329\n",
      "epoch 76 total_correct: 54743 loss: 14.463648796081543\n",
      "epoch 77 total_correct: 54720 loss: 14.325748264789581\n",
      "epoch 78 total_correct: 54625 loss: 14.558382004499435\n",
      "epoch 79 total_correct: 54803 loss: 14.183946639299393\n",
      "epoch 80 total_correct: 54883 loss: 14.041567340493202\n",
      "epoch 81 total_correct: 54882 loss: 14.027606755495071\n",
      "epoch 82 total_correct: 54871 loss: 13.973796769976616\n",
      "epoch 83 total_correct: 54810 loss: 14.018882557749748\n",
      "epoch 84 total_correct: 54866 loss: 14.021563485264778\n",
      "epoch 85 total_correct: 54893 loss: 13.959345802664757\n",
      "epoch 86 total_correct: 54848 loss: 14.0372384339571\n",
      "epoch 87 total_correct: 55008 loss: 13.560190662741661\n",
      "epoch 88 total_correct: 55045 loss: 13.566729187965393\n",
      "epoch 89 total_correct: 54955 loss: 13.593332588672638\n",
      "epoch 90 total_correct: 55078 loss: 13.531023785471916\n",
      "epoch 91 total_correct: 55060 loss: 13.540292218327522\n",
      "epoch 92 total_correct: 55127 loss: 13.276019021868706\n",
      "epoch 93 total_correct: 55134 loss: 13.226558908820152\n",
      "epoch 94 total_correct: 55000 loss: 13.568549290299416\n",
      "epoch 95 total_correct: 55096 loss: 13.30518727004528\n",
      "epoch 96 total_correct: 55100 loss: 13.284168481826782\n",
      "epoch 97 total_correct: 55265 loss: 12.975385755300522\n",
      "epoch 98 total_correct: 55216 loss: 13.041416987776756\n",
      "epoch 99 total_correct: 55254 loss: 12.847291260957718\n",
      "epoch 100 total_correct: 55223 loss: 13.010843083262444\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for batch in train_loader: # Get Batch\n",
    "        images, labels = batch \n",
    "\n",
    "        preds = net(images) # Pass Batch\n",
    "        loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # Calculate Gradients\n",
    "        optimizer.step() # Update Weights\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "    print(\n",
    "        \"epoch\", epoch+1, \n",
    "        \"total_correct:\", total_correct, \n",
    "        \"loss:\", total_loss\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9203833333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",total_correct/len(train_data) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./datatest\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d54406593c4b4c85abf91e55d23f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datatest\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ./datatest\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./datatest\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3add375543934f57914bd58cd69e5d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datatest\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ./datatest\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./datatest\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993d9e1f497144f6a45caed5e4a3904d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datatest\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ./datatest\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./datatest\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959d9550c6444e2f8b321c67aca083ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datatest\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./datatest\\FashionMNIST\\raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\soham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torchvision\\datasets\\mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "test_data=torchvision.datasets.FashionMNIST( \n",
    "    root='./datatest',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor()])\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
